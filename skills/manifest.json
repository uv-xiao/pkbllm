[
  {
    "canonical_path": "bootstrap/ml-knowledge-authoring",
    "description": "Create and curate new ML domain knowledge skills in this repo. Use when adding a new `knowledge/ML/*` skill, extending the curated ML taxonomy (model-architecture, training, distributed, serving, paper, kernel, agents), scaffolding a new skill folder, and ensuring naming (`uv-*`), licensing, and the generated `skills/` mirror stay consistent.",
    "name": "uv-bootstrap-ml-knowledge-authoring",
    "slug": "uv-bootstrap-ml-knowledge-authoring"
  },
  {
    "canonical_path": "bootstrap/skill-maintenance",
    "description": "Maintain and curate the pkbllm skills repository. Use when adding/importing a new skill, merging skills from external repos, updating or refactoring existing skills, regenerating the generated `skills/` mirror, or ensuring licensing/compliance and naming conventions (all skills must start with `uv-`).",
    "name": "uv-bootstrap-skill-maintenance",
    "slug": "uv-bootstrap-skill-maintenance"
  },
  {
    "canonical_path": "productivity/brainstorming",
    "description": "You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores user intent, requirements and design before implementation.",
    "name": "uv-brainstorming",
    "slug": "uv-brainstorming"
  },
  {
    "canonical_path": "human/slider/content-prompts",
    "description": "Convert raw material into per-page Content PROMPTs by analyzing content density, intent, and slide usage. Outputs $HUMAN_MATERIAL_PATH/slides/<deck>/prompts/content/<deck>.md. Use when the user has notes/materials and wants a well-planned per-page content prompt before styling.",
    "name": "uv-content-prompts",
    "slug": "uv-content-prompts"
  },
  {
    "canonical_path": "human/exercises/create-paper-exercises",
    "description": "Create learning exercises from a research paper (arXiv URL/PDF). Use when turning a paper into (1) a programming exercise (extract the core technique into a coding problem with tests) and (2) a modeling exercise (extract formulas/reasoning into calculation problems with worked solutions). Generates an exercise pack under $HUMAN_MATERIAL_PATH/exercises/<paper_slug>/ including local mini-skills to check answers and reveal golden solutions.",
    "name": "uv-create-paper-exercises",
    "slug": "uv-create-paper-exercises"
  },
  {
    "canonical_path": "knowledge/ML/distributed/deepspeed",
    "description": "Expert guidance for distributed training with DeepSpeed - ZeRO optimization stages, pipeline parallelism, FP16/BF16/FP8, 1-bit Adam, sparse attention",
    "name": "uv-deepspeed",
    "slug": "uv-deepspeed"
  },
  {
    "canonical_path": "productivity/dispatching-parallel-agents",
    "description": "Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies",
    "name": "uv-dispatching-parallel-agents",
    "slug": "uv-dispatching-parallel-agents"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/torchtitan",
    "description": "Provides PyTorch-native distributed LLM pretraining using torchtitan with 4D parallelism (FSDP2, TP, PP, CP). Use when pretraining Llama 3.1, DeepSeek V3, or custom models at scale from 8 to 512+ GPUs with Float8, torch.compile, and distributed checkpointing.",
    "name": "uv-distributed-llm-pretraining-torchtitan",
    "slug": "uv-distributed-llm-pretraining-torchtitan"
  },
  {
    "canonical_path": "productivity/executing-plans",
    "description": "Use when you have a written implementation plan to execute in a separate session with review checkpoints",
    "name": "uv-executing-plans",
    "slug": "uv-executing-plans"
  },
  {
    "canonical_path": "productivity/find-skills",
    "description": "Helps users discover and install agent skills when they ask questions like \"how do I do X\", \"find a skill for X\", \"is there a skill that can...\", or express interest in extending capabilities. This skill should be used when the user is looking for functionality that might exist as an installable skill.",
    "name": "uv-find-skills",
    "slug": "uv-find-skills"
  },
  {
    "canonical_path": "productivity/finishing-a-development-branch",
    "description": "Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup",
    "name": "uv-finishing-a-development-branch",
    "slug": "uv-finishing-a-development-branch"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/litgpt",
    "description": "Implements and trains LLMs using Lightning AI's LitGPT with 20+ pretrained architectures (Llama, Gemma, Phi, Qwen, Mistral). Use when need clean model implementations, educational understanding of architectures, or production fine-tuning with LoRA/QLoRA. Single-file implementations, no abstraction layers.",
    "name": "uv-implementing-llms-litgpt",
    "slug": "uv-implementing-llms-litgpt"
  },
  {
    "canonical_path": "human/init-human-material-repo",
    "description": "Initialize a dedicated HUMAN_MATERIAL_PATH git repository for generated human-facing materials. Use when a user asks to set up a new materials repo/folder for slides/manuscripts/exercises, create the expected file structure under $HUMAN_MATERIAL_PATH, and create a local-only .OPENROUTER_API_KEY file for slider rendering.",
    "name": "uv-init-human-material-repo",
    "slug": "uv-init-human-material-repo"
  },
  {
    "canonical_path": "human/scientific/literature-review",
    "description": "Conduct comprehensive literature reviews (systematic/narrative/scoping) across multiple databases, synthesize findings, and produce a well-cited review document. Use when planning and writing literature reviews or state-of-the-art surveys; prefer outputs under $HUMAN_MATERIAL_PATH/research/<topic>/.",
    "name": "uv-literature-review",
    "slug": "uv-literature-review"
  },
  {
    "canonical_path": "knowledge/ML/serving/llama-cpp",
    "description": "Runs LLM inference on CPU, Apple Silicon, and consumer GPUs without NVIDIA hardware. Use for edge deployment, M1/M2/M3 Macs, AMD/Intel GPUs, or when CUDA is unavailable. Supports GGUF quantization (1.5-8 bit) for reduced memory and 4-10\u00d7 speedup vs PyTorch on CPU.",
    "name": "uv-llama-cpp",
    "slug": "uv-llama-cpp"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/mamba",
    "description": "State-space model with O(n) complexity vs Transformers' O(n\u00b2). 5\u00d7 faster inference, million-token sequences, no KV cache. Selective SSM with hardware-aware design. Mamba-1 (d_state=16) and Mamba-2 (d_state=128, multi-head). Models 130M-2.8B on HuggingFace.",
    "name": "uv-mamba-architecture",
    "slug": "uv-mamba-architecture"
  },
  {
    "canonical_path": "knowledge/ML/training/miles",
    "description": "Provides guidance for enterprise-grade RL training using miles, a production-ready fork of slime. Use when training large MoE models with FP8/INT4, needing train-inference alignment, or requiring speculative RL for maximum throughput.",
    "name": "uv-miles-rl-training",
    "slug": "uv-miles-rl-training"
  },
  {
    "canonical_path": "knowledge/ML/paper/ml-paper-writing",
    "description": "Write publication-ready ML/AI papers for NeurIPS, ICML, ICLR, ACL, AAAI, COLM. Use when drafting papers from research repos, structuring arguments, verifying citations, or preparing camera-ready submissions. Includes LaTeX templates, reviewer guidelines, and citation verification workflows.",
    "name": "uv-ml-paper-writing",
    "slug": "uv-ml-paper-writing"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/moe-training",
    "description": "Train Mixture of Experts (MoE) models using DeepSpeed or HuggingFace. Use when training large-scale models with limited compute (5\u00d7 cost reduction vs dense models), implementing sparse architectures like Mixtral 8x7B or DeepSeek-V3, or scaling model capacity without proportional compute increase. Covers MoE architectures, routing mechanisms, load balancing, expert parallelism, and inference optimization.",
    "name": "uv-moe-training",
    "slug": "uv-moe-training"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/nanogpt",
    "description": "Educational GPT implementation in ~300 lines. Reproduces GPT-2 (124M) on OpenWebText. Clean, hackable code for learning transformers. By Andrej Karpathy. Perfect for understanding GPT architecture from scratch. Train on Shakespeare (CPU) or OpenWebText (multi-GPU).",
    "name": "uv-nanogpt",
    "slug": "uv-nanogpt"
  },
  {
    "canonical_path": "knowledge/ML/distributed/pytorch-fsdp2",
    "description": "Adds PyTorch FSDP2 (fully_shard) to training scripts with correct init, sharding, mixed precision/offload config, and distributed checkpointing. Use when models exceed single-GPU memory or when you need DTensor-based sharding with DeviceMesh.",
    "name": "uv-pytorch-fsdp2",
    "slug": "uv-pytorch-fsdp2"
  },
  {
    "canonical_path": "knowledge/ML/distributed/ray-train",
    "description": "Distributed training orchestration across clusters. Scales PyTorch/TensorFlow/HuggingFace from laptop to 1000s of nodes. Built-in hyperparameter tuning with Ray Tune, fault tolerance, elastic scaling. Use when training massive models across multiple machines or running distributed hyperparameter sweeps.",
    "name": "uv-ray-train",
    "slug": "uv-ray-train"
  },
  {
    "canonical_path": "human/read-arxiv-paper",
    "description": "Download and deeply read an arXiv paper (given an arXiv URL or id), then write a clear human-facing report with strong storytelling and logical reasoning. Use when asked to summarize/review an arXiv paper, extract key ideas, connect them to practice, and produce a report under $HUMAN_MATERIAL_PATH/research/<paper_slug>/report.md. Stores downloads under $HUMAN_MATERIAL_PATH/.references/ (configurable via $HUMAN_MATERIAL_PATH/.agents/config.toml or ~/.agents/config.toml).",
    "name": "uv-read-arxiv-paper",
    "slug": "uv-read-arxiv-paper"
  },
  {
    "canonical_path": "productivity/receiving-code-review",
    "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
    "name": "uv-receiving-code-review",
    "slug": "uv-receiving-code-review"
  },
  {
    "canonical_path": "productivity/requesting-code-review",
    "description": "Use when completing tasks, implementing major features, or before merging to verify work meets requirements",
    "name": "uv-requesting-code-review",
    "slug": "uv-requesting-code-review"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/rwkv",
    "description": "RNN+Transformer hybrid with O(n) inference. Linear time, infinite context, no KV cache. Train like GPT (parallel), infer like RNN (sequential). Linux Foundation AI project. Production at Windows, Office, NeMo. RWKV-7 (March 2025). Models up to 14B parameters.",
    "name": "uv-rwkv-architecture",
    "slug": "uv-rwkv-architecture"
  },
  {
    "canonical_path": "human/scientific/scientific-schematics",
    "description": "Create publication-quality scientific diagrams via OpenRouter image models with smart iterative refinement and automated quality review. Use when generating figures for papers/reports/slides (architectures, system diagrams, flowcharts, pathways). Prefer saving outputs under $HUMAN_MATERIAL_PATH/research/<topic>/figures/.",
    "name": "uv-scientific-schematics",
    "slug": "uv-scientific-schematics"
  },
  {
    "canonical_path": "human/scientific/scientific-writing",
    "description": "Write and revise scientific manuscripts in full paragraphs (not bullet points), using a two-stage workflow (outline \u2192 prose). Use when drafting IMRAD sections, applying reporting guidelines (CONSORT/STROBE/PRISMA), formatting citations (APA/AMA/Vancouver), and producing publishable writing in the HUMAN materials repo (usually under $HUMAN_MATERIAL_PATH/manuscripts/ or $HUMAN_MATERIAL_PATH/research/).",
    "name": "uv-scientific-writing",
    "slug": "uv-scientific-writing"
  },
  {
    "canonical_path": "knowledge/ML/serving/vllm",
    "description": "Serves LLMs with high throughput using vLLM's PagedAttention and continuous batching. Use when deploying production LLM APIs, optimizing inference latency/throughput, or serving models with limited GPU memory. Supports OpenAI-compatible endpoints, quantization (GPTQ/AWQ/FP8), and tensor parallelism.",
    "name": "uv-serving-llms-vllm",
    "slug": "uv-serving-llms-vllm"
  },
  {
    "canonical_path": "knowledge/ML/serving/sglang",
    "description": "Fast structured generation and serving for LLMs with RadixAttention prefix caching. Use for JSON/regex outputs, constrained decoding, agentic workflows with tool calls, or when you need 5\u00d7 faster inference than vLLM with prefix sharing. Powers 300,000+ GPUs at xAI, AMD, NVIDIA, and LinkedIn.",
    "name": "uv-sglang",
    "slug": "uv-sglang"
  },
  {
    "canonical_path": "human/slider/slider-plan",
    "description": "Plan the slider workflow end-to-end by selecting which repo skills to run (content-prompts, styled-prompts, styled-artifacts) based on the user\u2019s starting input (materials or existing prompts) and requested output (content prompt, styled prompt, images, PDF, PPTX). Uses $HUMAN_MATERIAL_PATH/slides/<deck>/ as the working root.",
    "name": "uv-slider-plan",
    "slug": "uv-slider-plan"
  },
  {
    "canonical_path": "knowledge/ML/training/slime",
    "description": "Provides guidance for LLM post-training with RL using slime, a Megatron+SGLang framework. Use when training GLM models, implementing custom data generation workflows, or needing tight Megatron-LM integration for RL scaling.",
    "name": "uv-slime-rl-training",
    "slug": "uv-slime-rl-training"
  },
  {
    "canonical_path": "knowledge/ML/model-architecture/speculative-decoding",
    "description": "Accelerate LLM inference using speculative decoding, Medusa multiple heads, and lookahead decoding techniques. Use when optimizing inference speed (1.5-3.6\u00d7 speedup), reducing latency for real-time applications, or deploying models with limited compute. Covers draft models, tree-based attention, Jacobi iteration, parallel token generation, and production deployment strategies.",
    "name": "uv-speculative-decoding",
    "slug": "uv-speculative-decoding"
  },
  {
    "canonical_path": "human/slider/styled-artifacts",
    "description": "Generate slide images and final PDF/PPTX from v2 styled prompts ($HUMAN_MATERIAL_PATH/slides/<deck>/prompts/styled/<deck>.md), storing intermediates in $HUMAN_MATERIAL_PATH/slides/<deck>/artifacts/<deck>/work/. Use when the user asks to render/generate/export slides from a Styled PROMPT into images/PDF/PPTX.",
    "name": "uv-styled-artifacts",
    "slug": "uv-styled-artifacts"
  },
  {
    "canonical_path": "human/slider/styled-prompts",
    "description": "Convert per-page Content PROMPTs into design-complete Styled PROMPTs using a Markdown style brief, inferring the best layout per page during creation. Outputs $HUMAN_MATERIAL_PATH/slides/<deck>/prompts/styled/<deck>.md, ready for image/PDF/PPT generation.",
    "name": "uv-styled-prompts",
    "slug": "uv-styled-prompts"
  },
  {
    "canonical_path": "productivity/subagent-driven-development",
    "description": "Use when executing implementation plans with independent tasks in the current session",
    "name": "uv-subagent-driven-development",
    "slug": "uv-subagent-driven-development"
  },
  {
    "canonical_path": "productivity/systematic-debugging",
    "description": "Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes",
    "name": "uv-systematic-debugging",
    "slug": "uv-systematic-debugging"
  },
  {
    "canonical_path": "knowledge/ML/serving/tensorrt-llm",
    "description": "Optimizes LLM inference with NVIDIA TensorRT for maximum throughput and lowest latency. Use for production deployment on NVIDIA GPUs (A100/H100), when you need 10-100x faster inference than PyTorch, or for serving models with quantization (FP8/INT4), in-flight batching, and multi-GPU scaling.",
    "name": "uv-tensorrt-llm",
    "slug": "uv-tensorrt-llm"
  },
  {
    "canonical_path": "productivity/test-driven-development",
    "description": "Use when implementing any feature or bugfix, before writing implementation code",
    "name": "uv-test-driven-development",
    "slug": "uv-test-driven-development"
  },
  {
    "canonical_path": "productivity/using-git-worktrees",
    "description": "Use when starting feature work that needs isolation from current workspace or before executing implementation plans - creates isolated git worktrees with smart directory selection and safety verification",
    "name": "uv-using-git-worktrees",
    "slug": "uv-using-git-worktrees"
  },
  {
    "canonical_path": "common/using-pkb",
    "description": "Use pkbllm skills effectively. Use at the start of a session when working from a pkbllm repo checkout: discover which `uv-*` skill to invoke, understand the canonical-vs-generated layout (don\u2019t edit `skills/`), install/list skills via Skills-CLI, and follow HUMAN_MATERIAL_PATH conventions (slides/research/exercises plus .references/ downloads with config.toml overrides).",
    "name": "uv-using-pkb",
    "slug": "uv-using-pkb"
  },
  {
    "canonical_path": "productivity/using-superpowers",
    "description": "Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions",
    "name": "uv-using-superpowers",
    "slug": "uv-using-superpowers"
  },
  {
    "canonical_path": "productivity/verification-before-completion",
    "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
    "name": "uv-verification-before-completion",
    "slug": "uv-verification-before-completion"
  },
  {
    "canonical_path": "knowledge/ML/training/verl",
    "description": "Provides guidance for training LLMs with reinforcement learning using verl (Volcano Engine RL). Use when implementing RLHF, GRPO, PPO, or other RL algorithms for LLM post-training at scale with flexible infrastructure backends.",
    "name": "uv-verl-rl-training",
    "slug": "uv-verl-rl-training"
  },
  {
    "canonical_path": "productivity/writing-plans",
    "description": "Use when you have a spec or requirements for a multi-step task, before touching code",
    "name": "uv-writing-plans",
    "slug": "uv-writing-plans"
  },
  {
    "canonical_path": "productivity/writing-skills",
    "description": "Use when creating new skills, editing existing skills, or verifying skills work before deployment",
    "name": "uv-writing-skills",
    "slug": "uv-writing-skills"
  }
]
